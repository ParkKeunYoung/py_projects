{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 머신러닝의 지도학습(변수,정답)의 한 알고리즘 사용\n",
    "- 나이브 베이즈 분류\n",
    "- Naive Bayes Classifier\n",
    "- 두 사건을 서로 독립적이라고 가정, 각각의 조건부 확률을 계산\n",
    "- 방식\n",
    " > 샘플 문장 제시 => 긍정/부정인지 답안제시\n",
    " > 학습(문자를 형태소 분해를 해서 학습용 데이터로 구성)\n",
    " > 학습후 모델이 생성이 되고 이를 통해서 한번도 접하지 못한 문장을 받아서 예측!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos : 긍정\n",
    "# neg : 부정\n",
    "# 연습용(학습용) 데이터 : 학습용과 테스트용 (75:25)\n",
    "train = [ ('i like you','pos'), \n",
    "          ('i hate you','neg'), \n",
    "          ('you like me','neg'), \n",
    "          ('i like her','pos') ]\n",
    "# i가 들어가면 긍정인가?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('i like you', 'pos')\n",
      "i\n",
      "like\n",
      "you\n",
      "('i hate you', 'neg')\n",
      "i\n",
      "hate\n",
      "you\n",
      "('you like me', 'neg')\n",
      "you\n",
      "like\n",
      "me\n",
      "('i like her', 'pos')\n",
      "i\n",
      "like\n",
      "her\n"
     ]
    }
   ],
   "source": [
    "for sentence in train:\n",
    "    print(  sentence )\n",
    "    # word_tokenize() => 한글의 형태소 분해 과정 유사\n",
    "    for word in word_tokenize(sentence[0]):\n",
    "        # 알파벳은 대문자 혹은 소문자로 일치시킨다\n",
    "        print( word.lower() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hate', 'you', 'her', 'me', 'i', 'like']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 전체 문장에서 형태소로 분해하여 중복을 제거하여 리스트로 담아라 한줄로\n",
    "# all_words = \n",
    "all_words = list( set( [ word.lower() \n",
    "                         for sentence in train  \n",
    "                         for word in word_tokenize(sentence[0]) ] ) )\n",
    "all_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos {'hate': False, 'you': True, 'her': False, 'me': False, 'i': True, 'like': True}\n",
      "neg {'hate': True, 'you': True, 'her': False, 'me': False, 'i': True, 'like': False}\n",
      "neg {'hate': False, 'you': True, 'her': False, 'me': True, 'i': False, 'like': True}\n",
      "pos {'hate': False, 'you': False, 'her': True, 'me': False, 'i': True, 'like': True}\n"
     ]
    }
   ],
   "source": [
    "# 훈련용 텍스트 문장에 all_words에 내용을 대비하여 해당 말뭉치가 있는지 없는지 체킹\n",
    "for x in train:\n",
    "    print( x[1], { word:( word in word_tokenize(x[0]) ) for word in all_words  } )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'hate': False,\n",
       "   'you': True,\n",
       "   'her': False,\n",
       "   'me': False,\n",
       "   'i': True,\n",
       "   'like': True},\n",
       "  'pos'),\n",
       " ({'hate': True,\n",
       "   'you': True,\n",
       "   'her': False,\n",
       "   'me': False,\n",
       "   'i': True,\n",
       "   'like': False},\n",
       "  'neg'),\n",
       " ({'hate': False,\n",
       "   'you': True,\n",
       "   'her': False,\n",
       "   'me': True,\n",
       "   'i': False,\n",
       "   'like': True},\n",
       "  'neg'),\n",
       " ({'hate': False,\n",
       "   'you': False,\n",
       "   'her': True,\n",
       "   'me': False,\n",
       "   'i': True,\n",
       "   'like': True},\n",
       "  'pos')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = [ ( { word:( word in word_tokenize(x[0]) ) for word in all_words  }, x[1] ) \n",
    "      for x in train ]\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습\n",
    "# 알고리즘 생성및 학습을 한번에 진행\n",
    "classifier = nltk.NaiveBayesClassifier.train( t )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                      me = False             pos : neg    =      1.7 : 1.0\n",
      "                    hate = False             pos : neg    =      1.7 : 1.0\n",
      "                       i = True              pos : neg    =      1.7 : 1.0\n",
      "                     you = True              neg : pos    =      1.7 : 1.0\n",
      "                     her = False             neg : pos    =      1.7 : 1.0\n",
      "                    like = True              pos : neg    =      1.7 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features()\n",
    "# 학습 결과, 분류의 결과치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 새로운 단어 \n",
    "test_sentence = 'i like MeRui'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hate': False,\n",
       " 'you': False,\n",
       " 'her': False,\n",
       " 'me': False,\n",
       " 'i': True,\n",
       " 'like': True}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 이 문장에 위의 표현처럼 구성 => {}\n",
    "test_sentence_feature = { word.lower():( word in word_tokenize(test_sentence) ) \n",
    "                          for word in all_words  }\n",
    "test_sentence_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pos'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예측\n",
    "classifier.classify( test_sentence_feature )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 한글 데이터 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\jpype\\_core.py:210: UserWarning: \n",
      "-------------------------------------------------------------------------------\n",
      "Deprecated: convertStrings was not specified when starting the JVM. The default\n",
      "behavior in JPype will be False starting in JPype 0.8. The recommended setting\n",
      "for new code is convertStrings=False.  The legacy value of True was assumed for\n",
      "this session. If you are a user of an application that reported this warning,\n",
      "please file a ticket with the developer.\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "  \"\"\")\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Okt\n",
    "pos_tagger = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 데이터\n",
    "train = [ ('아웃백이 좋아','pos'),\n",
    "          ('애슐리도 좋아','pos'),\n",
    "          ('난 자연당이 싫어','neg'),\n",
    "          ('아웃백은 아주 좋은 식당이야','pos'),\n",
    "          ('난 수업 마치고 아웃백에 갈거야','pos'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'갈거야',\n",
       " '난',\n",
       " '마치고',\n",
       " '수업',\n",
       " '식당이야',\n",
       " '싫어',\n",
       " '아웃백에',\n",
       " '아웃백은',\n",
       " '아웃백이',\n",
       " '아주',\n",
       " '애슐리도',\n",
       " '자연당이',\n",
       " '좋아',\n",
       " '좋은'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 말뭉치 준비\n",
    "# 중복제거, \n",
    "# nltk의 토큰나이저 사용시 공백기준으로 명사품사등을 쪼개지 않고 그대로 워드화 하였다\n",
    "all_words = set(  word for sentence in train\n",
    "                  for word in  word_tokenize( sentence[0] ) )\n",
    "all_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'자연당이': False,\n",
       "   '싫어': False,\n",
       "   '마치고': False,\n",
       "   '식당이야': False,\n",
       "   '좋은': False,\n",
       "   '아웃백이': True,\n",
       "   '수업': False,\n",
       "   '좋아': True,\n",
       "   '갈거야': False,\n",
       "   '난': False,\n",
       "   '아웃백은': False,\n",
       "   '애슐리도': False,\n",
       "   '아웃백에': False,\n",
       "   '아주': False},\n",
       "  'pos'),\n",
       " ({'자연당이': False,\n",
       "   '싫어': False,\n",
       "   '마치고': False,\n",
       "   '식당이야': False,\n",
       "   '좋은': False,\n",
       "   '아웃백이': False,\n",
       "   '수업': False,\n",
       "   '좋아': True,\n",
       "   '갈거야': False,\n",
       "   '난': False,\n",
       "   '아웃백은': False,\n",
       "   '애슐리도': True,\n",
       "   '아웃백에': False,\n",
       "   '아주': False},\n",
       "  'pos'),\n",
       " ({'자연당이': True,\n",
       "   '싫어': True,\n",
       "   '마치고': False,\n",
       "   '식당이야': False,\n",
       "   '좋은': False,\n",
       "   '아웃백이': False,\n",
       "   '수업': False,\n",
       "   '좋아': False,\n",
       "   '갈거야': False,\n",
       "   '난': True,\n",
       "   '아웃백은': False,\n",
       "   '애슐리도': False,\n",
       "   '아웃백에': False,\n",
       "   '아주': False},\n",
       "  'neg'),\n",
       " ({'자연당이': False,\n",
       "   '싫어': False,\n",
       "   '마치고': False,\n",
       "   '식당이야': True,\n",
       "   '좋은': True,\n",
       "   '아웃백이': False,\n",
       "   '수업': False,\n",
       "   '좋아': False,\n",
       "   '갈거야': False,\n",
       "   '난': False,\n",
       "   '아웃백은': True,\n",
       "   '애슐리도': False,\n",
       "   '아웃백에': False,\n",
       "   '아주': True},\n",
       "  'pos'),\n",
       " ({'자연당이': False,\n",
       "   '싫어': False,\n",
       "   '마치고': True,\n",
       "   '식당이야': False,\n",
       "   '좋은': False,\n",
       "   '아웃백이': False,\n",
       "   '수업': True,\n",
       "   '좋아': False,\n",
       "   '갈거야': True,\n",
       "   '난': True,\n",
       "   '아웃백은': False,\n",
       "   '애슐리도': False,\n",
       "   '아웃백에': True,\n",
       "   '아주': False},\n",
       "  'pos')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = [ ( { word:( word in word_tokenize(x[0]) ) for word in all_words  }, x[1] ) \n",
    "      for x in train ]\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습\n",
    "classifier = nltk.NaiveBayesClassifier.train( t )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                       난 = True              neg : pos    =      2.5 : 1.0\n",
      "                      좋아 = False             neg : pos    =      1.5 : 1.0\n",
      "                     마치고 = False             neg : pos    =      1.1 : 1.0\n",
      "                    아웃백이 = False             neg : pos    =      1.1 : 1.0\n",
      "                    애슐리도 = False             neg : pos    =      1.1 : 1.0\n",
      "                      수업 = False             neg : pos    =      1.1 : 1.0\n",
      "                      좋은 = False             neg : pos    =      1.1 : 1.0\n",
      "                     갈거야 = False             neg : pos    =      1.1 : 1.0\n",
      "                    식당이야 = False             neg : pos    =      1.1 : 1.0\n",
      "                    아웃백은 = False             neg : pos    =      1.1 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측할 문장\n",
    "test_sentence = '난 수업을 마치고 자연당에 갈거야'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('아웃백이 좋아', 'pos'),\n",
       " ('애슐리도 좋아', 'pos'),\n",
       " ('난 자연당이 싫어', 'neg'),\n",
       " ('아웃백은 아주 좋은 식당이야', 'pos'),\n",
       " ('난 수업 마치고 아웃백에 갈거야', 'pos')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'자연당이': False,\n",
       " '싫어': False,\n",
       " '마치고': True,\n",
       " '식당이야': False,\n",
       " '좋은': False,\n",
       " '아웃백이': False,\n",
       " '수업': False,\n",
       " '좋아': False,\n",
       " '갈거야': True,\n",
       " '난': True,\n",
       " '아웃백은': False,\n",
       " '애슐리도': False,\n",
       " '아웃백에': False,\n",
       " '아주': False}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예측할 문장의 데이터화 \n",
    "test_sentence_feature = { word.lower():( word in word_tokenize(test_sentence) ) \n",
    "                          for word in all_words  }\n",
    "test_sentence_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pos'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예측\n",
    "classifier.classify( test_sentence_feature )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위의 방식으로 진행을 해보면, 훈련에 필요한 다량의 데이터(문장, 상황) 필요하다\n",
    "# 훈련량이 적거나, 데이터가 적거나, 부정확하다 => 정확도가 떨어진다\n",
    "# 절차적인것만 체크, 한계적인 상황도 고려\n",
    "# 지도학습은 정답을 알고 있어야 한다. 다양하게 구성할수 있는 문장에 대한 판단이\n",
    "# 쉽지않다. => 많은 문장과 문서중에서 유사한 문자을 찾아내고 => \n",
    "# 문장을 백터로 표현하여, 백터간의 거리를 구하여 해결 => 문장의 유사도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1은 임시값 -> 이값들은 향후 하이퍼 파라미터 튜딩이라는 주제에서 값을 다변화하여\n",
    "# 조합 테스트를 수행\n",
    "vectorizer =  CountVectorizer(min_df=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 많은 문장을 훈련시켜야 한다, 몇가지 샘플로 진행\n",
    "contents = ['성건이랑 술마시고 싶지만 바쁜데 어떻하죠?',\n",
    "            '성건이는 공원에서 산책하고 노는 것을 싫어해요',\n",
    "            '성건이는 공원에서 노는 것도 싫어해요. 이상해요.',\n",
    "            '먼 곳으로 여행을 떠나고 싶은데 너무 바빠서 그러질 못하고 있어요.'\n",
    "           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorizer.fit_transform( contents )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22, ['것도', '것을', '곳으로', '공원에서', '그러질'])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature : 특징들 => 변수\n",
    "len(tmp), tmp[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((22, 4), array([[0, 0, 1, 0],\n",
       "        [0, 1, 0, 0],\n",
       "        [0, 0, 0, 1],\n",
       "        [0, 1, 1, 0],\n",
       "        [0, 0, 0, 1],\n",
       "        [0, 0, 0, 1],\n",
       "        [0, 1, 1, 0],\n",
       "        [0, 0, 0, 1],\n",
       "        [0, 0, 0, 1],\n",
       "        [0, 0, 0, 1],\n",
       "        [1, 0, 0, 0],\n",
       "        [0, 1, 0, 0],\n",
       "        [0, 1, 1, 0],\n",
       "        [1, 0, 0, 0],\n",
       "        [1, 0, 0, 0],\n",
       "        [0, 1, 1, 0],\n",
       "        [0, 0, 0, 1],\n",
       "        [1, 0, 0, 0],\n",
       "        [1, 0, 0, 0],\n",
       "        [0, 0, 0, 1],\n",
       "        [0, 0, 1, 0],\n",
       "        [0, 0, 0, 1]], dtype=int64))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 각 feature에 대한 백터값 \n",
    "trans = X.toarray().transpose()\n",
    "trans.shape, trans\n",
    "# '것도' 라는 feature는\n",
    "# 훈련용 전체문장 4개중 3번째에 등장한다\n",
    "# 0, 0, 1, 0 이라는 백터값을 가지게 된다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples, num_features =  X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문장이 4개\n",
    "num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문장 4개에서 추출한 말뭉치 22개\n",
    "num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 새로운 문장\n",
    "new_post = ['성건이랑 공원에서 산책하고 놀고 싶어요']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_post_vec = vectorizer.transform( new_post )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = new_post_vec.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 22)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문장의 백터화\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유사도 판단을 하기위해서 거리 계산\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 거리계산\n",
    "def dis_raw( v1, v2 ):\n",
    "    delta = v1 - v2\n",
    "    return sp.linalg.norm( delta.toarray() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 샘플 문장을 반복하면서 이 문장과, 일일이 비교 -> 그중에 거리가 가장 짦은 문장이 선택\n",
    "# 그 문장이 가장 유사한 문장이다\n",
    "best_distance = 1000\n",
    "best_index    = None\n",
    "for i in range( num_samples ):\n",
    "    # 각 문장의 백터 정보를 리턴 \n",
    "    post_vec = X.getrow(i)  \n",
    "    # 비교 문장 : new_post_vec\n",
    "    # 거리 계산\n",
    "    d = dis_raw( post_vec,  new_post_vec )\n",
    "    #print( \"%d %f\" % (i, d) )\n",
    "    # 거리가, best_distance보다 작으면 세팅\n",
    "    if d < best_distance:\n",
    "        best_distance = d\n",
    "        best_index = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.23606797749979"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 최소거리 :\n",
    "best_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 그때의 인덱스\n",
    "best_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'성건이는 공원에서 산책하고 노는 것을 싫어해요'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 그때 문장은\n",
    "contents[best_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'성건이랑 공원에서 산책하고 놀고 싶어요'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'성건이랑 공원에서 산책하고 놀고 싶어요'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -> nltk의 말뭉치는 한글과 딱히 맞지가 않다\n",
    "# 한글 전용 형태소 분석기를 활용하여 보다 정확하고, 의미있게 작업을 진행 목표로 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
